{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integral-break",
   "metadata": {},
   "source": [
    "# Interview experiments for blenderbot\n",
    "\n",
    "In order to get Freja to act as an inteviewer we have to constrain her. Blenderbot(the model) is trained as an open-domain chat bot, which makes her very explorative when it comes to asking questions.\n",
    "\n",
    "#### Approach:\n",
    "- Hard code a set of interview questions\n",
    "- System for determining when it's time to move on to next question\n",
    "- Experiment with the dialogue context she gets at each pass of the conversation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swiss-boating",
   "metadata": {},
   "source": [
    "## Google translate for translating text back and forth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acquired-binding",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googletrans import Translator\n",
    "\n",
    "translator = Translator()\n",
    "def sv_to_en(text):\n",
    "    # Translates text from swedish to english\n",
    "    out = translator.translate(text,src='sv',dest='en')\n",
    "    return out.text\n",
    "\n",
    "def en_to_sv(text):\n",
    "    # Translate text from english to swedish\n",
    "    out = translator.translate(text,src='en',dest='sv')\n",
    "    return out.text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-shanghai",
   "metadata": {},
   "source": [
    "# Blenderbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "attended-founder",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BlenderbotTokenizer, BlenderbotForConditionalGeneration\n",
    "from torch import no_grad\n",
    "mname = 'facebook/blenderbot-1B-distill' # options: 'facebook/blenderbot_small-90M' , 'facebook/blenderbot-400M-distill' ,'facebook/blenderbot-3B'\n",
    "model = BlenderbotForConditionalGeneration.from_pretrained(mname)\n",
    "tokenizer = BlenderbotTokenizer.from_pretrained(mname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "premium-toddler",
   "metadata": {},
   "source": [
    "## BlenderConversation is a class for storing the conversation with blenderbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "strange-bread",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlenderConversation:\n",
    "    \n",
    "    def __init__(self,lang,description='No description'):\n",
    "        self.lang = lang\n",
    "        self.description = description\n",
    "        self.bot_text = []\n",
    "        self.user_text = []\n",
    "        self.user_turn = True\n",
    "        \n",
    "        \n",
    "    def add_user_text(self,text):\n",
    "        if self.user_turn:\n",
    "            self.user_text.append(text)\n",
    "            self.user_turn = False\n",
    "        else:\n",
    "            raise ValueError(\"It's the bot's turn to add a reply to the conversation\")\n",
    "        return\n",
    "    \n",
    "    def add_bot_text(self,text):\n",
    "        if not self.user_turn:\n",
    "            self.bot_text.append(text)\n",
    "            self.user_turn = True\n",
    "        else:\n",
    "            raise ValueError(\"It's the user's turn to add an input to the conversation\")\n",
    "        return\n",
    "    \n",
    "    def pop(self):\n",
    "        if self.user_turn:\n",
    "            self.bot_text.pop()\n",
    "            self.user_turn = False\n",
    "        else:\n",
    "            self.user_text.pop()\n",
    "            self.user_turn = True\n",
    "        return\n",
    "    \n",
    "    def get_bot_replies():\n",
    "        return self.bot_text\n",
    "    \n",
    "    def get_user_replies():\n",
    "        return self.user_text\n",
    "        \n",
    "    def get_dialogue_history(self,max_len=100):\n",
    "        # Returns string of the dialogue history with bot and user inputs separated with '\\n'\n",
    "        # max_len set to default 110 as model has max input length 128 and we want some space for new input \n",
    "        history = ''\n",
    "        tokens_left = max_len\n",
    "        if self.user_turn:\n",
    "            # Start backwards from bot_text\n",
    "            for i in reversed(range(len(self.user_text))):\n",
    "                bot_text = self.bot_text[i]\n",
    "                user_text = self.user_text[i]\n",
    "                nbr_tokens = len(tokenizer(bot_text)['input_ids'])  + len(tokenizer(user_text)['input_ids'])\n",
    "                if  nbr_tokens < tokens_left: # This is not fool proof as the model tokenizer tokenizes differently\n",
    "                    history = user_text + '\\n' + bot_text + '\\n' + history\n",
    "                    tokens_left -= (nbr_tokens + 2)\n",
    "                else:\n",
    "                    break\n",
    "                                \n",
    "        else:\n",
    "            # Start backwards from user_text\n",
    "            history = self.user_text[-1]\n",
    "            tokens_left -= len(tokenizer(history)['input_ids'])\n",
    "            for i in reversed(range(len(self.user_text)-1)):\n",
    "                bot_text = self.bot_text[i]\n",
    "                user_text = self.user_text[i]\n",
    "                nbr_tokens = len(bot_text.split()) + len(user_text.split())\n",
    "                if  nbr_tokens < tokens_left: # This is not fool proof as the model tokenizer tokenizes differently\n",
    "                    history = user_text + '\\n' + bot_text + '\\n' + history\n",
    "                    tokens_left -= (nbr_tokens + 2)\n",
    "                else:\n",
    "                    break\n",
    "        return history\n",
    "        \n",
    "    def to_txt(self,file='None'):\n",
    "        # Writes the dialogue to txt file in subdirectory\n",
    "        text = '####################################\\n' + 'Conversation description: ' + self.description + '\\n\\n'\n",
    "        if self.user_turn:\n",
    "            for i in range(len(self.user_text)):\n",
    "                text = text + 'User>>> '+ self.user_text[i] + '\\n Bot>>> ' + self.bot_text[i] + '\\n'\n",
    "        else:\n",
    "            for i in range(len(self.bot_text)):\n",
    "                text = text + 'User>>> '+ self.user_text[i] + '\\n Bot>>> ' + self.bot_text[i] + '\\n'\n",
    "            text = text + 'User>>> ' + self.user_text[-1]\n",
    "        \n",
    "        if file is None:\n",
    "            if self.lang == 'sv':\n",
    "                file = 'interview_sv.txt'\n",
    "            else:\n",
    "                file = 'interview_en.txt'\n",
    "        \n",
    "        text = text + '\\n\\n'\n",
    "        file_path = '02_interview_output/' + file\n",
    "        with open(file_path,'a') as f:\n",
    "            f.write(text)\n",
    "        return\n",
    "         \n",
    "    \n",
    "    def print_dialogue(self):\n",
    "        # Prints the dialogue \n",
    "        text = ''\n",
    "        if self.user_turn:\n",
    "            for i in range(len(self.user_text)):\n",
    "                text = text + 'User>>> '+ self.user_text[i] + '\\n Bot>>> ' + self.bot_text[i] + '\\n'\n",
    "        else:\n",
    "            for i in range(len(self.bot_text)):\n",
    "                text = text + 'User>>> '+ self.user_text[i] + '\\n Bot>>> ' + self.bot_text[i] + '\\n'\n",
    "            text = text + 'User>>> ' + self.user_text[-1]\n",
    "        print(text)\n",
    "        return\n",
    "\n",
    "\n",
    "def strip_token(line):\n",
    "    # Removes SOS and EOS tokens from blenderbot reply\n",
    "    line = line.replace('<s>','')\n",
    "    line = line.replace('</s>','')\n",
    "    return line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-bryan",
   "metadata": {},
   "source": [
    "##  Helper functions for regulating the context \n",
    "#### First a helper function for taking care of the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "lyric-intervention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blender_history_chatting(user_input,convo_sv,convo_en):\n",
    "    #assert convo_sv.lang == 'en' and convo_en.lang =='sv'\n",
    "    \n",
    "    translated_user_input = sv_to_en(user_input)\n",
    "    nbr_tokens = len(tokenizer(translated_user_input)['input_ids'])\n",
    "    max_len = 126 - nbr_tokens\n",
    "    #set_trace()\n",
    "    context = convo_en.get_dialogue_history(max_len=max_len)\n",
    "    \n",
    "    convo_sv.add_user_text(user_input)\n",
    "    convo_en.add_user_text(translated_user_input)\n",
    "    \n",
    "    model_input = context + '\\n' + translated_user_input\n",
    "\n",
    "    with no_grad():\n",
    "        inputs = tokenizer([model_input], return_tensors='pt')\n",
    "        reply_ids = model.generate(**inputs)\n",
    "\n",
    "        reply = strip_token(tokenizer.batch_decode(reply_ids)[0]) # Decodes tokens and strips <s> and </s>  \n",
    "    \n",
    "    convo_en.add_bot_text(reply)\n",
    "    convo_sv.add_bot_text(en_to_sv(reply))\n",
    "    convo_sv.print_dialogue()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "powered-brooks",
   "metadata": {},
   "source": [
    "####  Subject chatting helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fossil-conversation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def blender_subject_chatting(user_input,convo_sv,convo_en):\n",
    "    #assert convo_sv.lang == 'en' and convo_en.lang =='sv'\n",
    "    \n",
    "    translated_user_input = sv_to_en(user_input)\n",
    "    \n",
    "    # Add inputs to conversations\n",
    "    convo_sv.add_user_text(user_input)\n",
    "    convo_en.add_user_text(translated_user_input)\n",
    "    \n",
    "    if len(convo_en.bot_text) == 0:\n",
    "        model_input = subject + '\\n' +  translated_user_input\n",
    "    else:\n",
    "        model_input = subject + '\\n' + convo_en.bot_text[-1] + '\\n' +  translated_user_input\n",
    "\n",
    "    with no_grad():\n",
    "        inputs = tokenizer([model_input], return_tensors='pt')\n",
    "        reply_ids = model.generate(**inputs)\n",
    "\n",
    "        reply = strip_token(tokenizer.batch_decode(reply_ids)[0]) # Decodes tokens and strips <s> and </s>  \n",
    "    \n",
    "    convo_en.add_bot_text(reply)\n",
    "    convo_sv.add_bot_text(en_to_sv(reply))\n",
    "    convo_sv.print_dialogue()\n",
    "    return\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accompanied-ribbon",
   "metadata": {},
   "source": [
    "## Class for keeping track of the interview and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "minimal-clock",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Du har sökt jobbet som car mech. Vad är det som du tycker verkar vara roligt med detta arbetet?',\n",
       " 'Om du ska arbeta som car mech så är det bra om du har erfarenhet från YY. Kan du berätta lite om du har sådan erfarenhet?',\n",
       " 'Vad är din bästa erfarenhet från dina tidigare arbeten?',\n",
       " 'Vad gör att du skulle passa bra som car mech?',\n",
       " 'Är det någonting som du vill fråga om detta arbetet?']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just a place to store questions instead of having txt files for now\n",
    "questions = ['Du har sökt jobbet som {}. Vad är det som du tycker verkar vara roligt med detta arbetet?', \n",
    "                       'Om du ska arbeta som {} så är det bra om du har erfarenhet från YY. Kan du berätta lite om du har sådan erfarenhet?',\n",
    "                       'Vad är din bästa erfarenhet från dina tidigare arbeten?',\n",
    "                       'Vad gör att du skulle passa bra som {}?',\n",
    "                       'Är det någonting som du vill fråga om detta arbetet?']\n",
    "format_question = [1,1,0,1,0]\n",
    "interview_questions= zip(questions,format_question)\n",
    "test = [question.format('car mech') if to_format else question for (question, to_format) in interview_questions]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "manual-collins",
   "metadata": {},
   "outputs": [],
   "source": [
    "class InterviewWorld:\n",
    "# Class that keeps\n",
    "\n",
    "    def __init__(self,job,name):\n",
    "        # TODO: More sophisticated questions/greeting drawn from txt file(?) and formated with name and job\n",
    "        self.questions = [if to_format question.format(job) else question for (question, to_format) in interview_questions]\n",
    "        self.greeting = 'Hello, and welcome to this interview. How are you today, {}?'.format(name)\n",
    "        \n",
    "        self.job = job\n",
    "        self.human_name = name\n",
    "        self.freja = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.translator = translator\n",
    "        self.episode_done = False\n",
    "        \n",
    "        desc = 'InterviewWorld: ' + job + ' and  ' + name\n",
    "        self.conversation_sv = BlenderConversation(lang='sv',description=desc)\n",
    "        self.conversation_en = BlenderConversation(lang='en',description=desc)\n",
    "        \n",
    "    def observe(user_input):\n",
    "        # Observe the user input and update internal states\n",
    "        # Check if user wants to quit/no questions left --> self.episode_done = True\n",
    "        \n",
    "        translated\n",
    "        return\n",
    "        \n",
    "    def act():\n",
    "        # Pull message from queue\n",
    "        \n",
    "        if episode_done:\n",
    "            self.conversation_sv.to_txt()\n",
    "            self.conversation_en.to_txt()\n",
    "            return 'Tack för din intervju'\n",
    "        \n",
    "        else:\n",
    "        return\n",
    "        \n",
    "        \n",
    "    def _strip_token(line):\n",
    "    # Removes SOS and EOS tokens from blenderbot reply\n",
    "    line = line.replace('<s>','')\n",
    "    line = line.replace('</s>','')\n",
    "    return line\n",
    "\n",
    "    def _interview_chat():\n",
    "        return\n",
    "\n",
    "    def _check_answer():\n",
    "        # TODO: \n",
    "        self.conversation_en.get_bot_replies()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enormous-garden",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "job = \n",
    "name = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
